#!/usr/bin/env python3
import asyncio
import aiohttp
import time
import json
from datetime import datetime
from collections import defaultdict
import statistics

class APIPerformanceTest:
    def __init__(self, api_url="http://localhost:8000"):
        self.api_url = api_url
        self.test_duration = 35  # seconds
        self.call_interval = 0.001  # seconds
        
        self.response_times = []
        self.api_calls_count = 0
        self.data_snapshots = []
        self.errors = []
        
    async def call_api(self, session, endpoint="/ctr/latest"):
        """API í˜¸ì¶œí•˜ê³  ì‘ë‹µì‹œê°„ ì¸¡ì •"""
        try:
            start_time = time.time()
            async with session.get(f"{self.api_url}{endpoint}") as response:
                data = await response.json()
                end_time = time.time()
                
                response_time = end_time - start_time
                self.response_times.append(response_time)
                self.api_calls_count += 1
                
                # window_end ê°’ ì¶”ì¶œ
                window_ends = []
                if isinstance(data, dict):
                    for product_data in data.values():
                        if isinstance(product_data, dict) and 'window_end' in product_data:
                            window_ends.append(product_data['window_end'])
                
                # ë°ì´í„° ìŠ¤ëƒ…ìƒ· ì €ì¥ (ë³€í™” ê°ì§€ìš©)
                current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3]
                self.data_snapshots.append({
                    "timestamp": current_time,
                    "response_time": response_time,
                    "data": data,
                    "window_ends": window_ends
                })
                
                print(f"[{current_time}] API Call #{self.api_calls_count} - "
                      f"Response time: {response_time:.3f}s - "
                      f"Window ends: {set(window_ends) if window_ends else 'None'}")
                
                return data
                
        except Exception as e:
            error_msg = f"API call failed: {str(e)}"
            self.errors.append(error_msg)
            print(f"ERROR: {error_msg}")
            return None
    
    def detect_window_end_changes(self):
        """window_end ê°’ ë³€í™” ê°ì§€ ë° ì§€ì†ì‹œê°„ ê³„ì‚°"""
        if len(self.data_snapshots) < 2:
            return []
            
        changes = []
        prev_window_ends = set(self.data_snapshots[0]["window_ends"])
        window_start_time = datetime.strptime(self.data_snapshots[0]["timestamp"], "%H:%M:%S.%f")
        
        for i, snapshot in enumerate(self.data_snapshots[1:], 1):
            current_window_ends = set(snapshot["window_ends"])
            current_time = datetime.strptime(snapshot["timestamp"], "%H:%M:%S.%f")
            
            # window_end ê°’ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if prev_window_ends != current_window_ends:
                # ì´ì „ ìœˆë„ìš°ì˜ ì§€ì†ì‹œê°„ ê³„ì‚° (ms ë‹¨ìœ„)
                duration_ms = (current_time - window_start_time).total_seconds() * 1000
                
                changes.append({
                    "change_number": len(changes) + 1,
                    "timestamp": snapshot["timestamp"],
                    "call_number": i + 1,
                    "prev_window_ends": sorted(prev_window_ends),
                    "current_window_ends": sorted(current_window_ends),
                    "new_windows": sorted(current_window_ends - prev_window_ends),
                    "removed_windows": sorted(prev_window_ends - current_window_ends),
                    "duration_ms": duration_ms
                })
                print(f"ğŸ”„ WINDOW_END CHANGE #{len(changes)} detected at {snapshot['timestamp']} (Call #{i + 1})")
                print(f"   Previous window lasted: {duration_ms:.0f}ms")
                print(f"   New windows: {sorted(current_window_ends - prev_window_ends)}")
                
                prev_window_ends = current_window_ends
                window_start_time = current_time
        
        # ë§ˆì§€ë§‰ ìœˆë„ìš°ì˜ ì§€ì†ì‹œê°„ë„ ê³„ì‚° (ms ë‹¨ìœ„)
        if changes and len(self.data_snapshots) > 0:
            last_snapshot = self.data_snapshots[-1]
            last_time = datetime.strptime(last_snapshot["timestamp"], "%H:%M:%S.%f")
            final_duration_ms = (last_time - window_start_time).total_seconds() * 1000
            
            print(f"ğŸ“Š Final window duration: {final_duration_ms:.0f}ms (until test end)")
                
        return changes
    
    def calculate_performance_metrics(self):
        """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        if not self.response_times:
            return {}
            
        return {
            "total_calls": self.api_calls_count,
            "total_errors": len(self.errors),
            "success_rate": (self.api_calls_count - len(self.errors)) / self.api_calls_count * 100,
            "avg_response_time": statistics.mean(self.response_times),
            "min_response_time": min(self.response_times),
            "max_response_time": max(self.response_times),
            "median_response_time": statistics.median(self.response_times),
            "p95_response_time": statistics.quantiles(self.response_times, n=20)[18] if len(self.response_times) >= 20 else max(self.response_times),
            "calls_per_second": self.api_calls_count / self.test_duration
        }
    
    async def run_test(self):
        """35ì´ˆê°„ 0.5ì´ˆë§ˆë‹¤ API í˜¸ì¶œí•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"ğŸš€ Starting API Performance Test")
        print(f"â±ï¸  Test Duration: {self.test_duration} seconds")
        print(f"ğŸ“ Call Interval: {self.call_interval} seconds")
        print(f"ğŸ¯ Expected Calls: ~{int(self.test_duration / self.call_interval)}")
        print(f"ğŸ”— API URL: {self.api_url}")
        print("-" * 80)
        
        start_time = time.time()
        
        async with aiohttp.ClientSession() as session:
            while time.time() - start_time < self.test_duration:
                await self.call_api(session)
                await asyncio.sleep(self.call_interval)
        
        print("-" * 80)
        print("âœ… Test completed!")
        
        # window_end ë³€í™” ê°ì§€
        changes = self.detect_window_end_changes()
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = self.calculate_performance_metrics()
        
        # ê²°ê³¼ ì¶œë ¥
        self.print_results(changes, metrics)
    
    def print_results(self, changes, metrics):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š TEST RESULTS")
        print("="*80)
        
        print(f"\nğŸ”„ WINDOW_END CHANGES:")
        print(f"ğŸ“Š Total window_end changes detected: {len(changes)}")
        if changes:
            print(f"âœ… Window end transitions successfully tracked!")
            total_duration_ms = 0
            for change in changes:
                print(f"   Change #{change['change_number']}: {change['timestamp']} (Call #{change['call_number']})")
                print(f"     â±ï¸  Previous window duration: {change['duration_ms']:.0f}ms")
                if change['new_windows']:
                    print(f"     â¡ï¸  New windows: {change['new_windows']}")
                total_duration_ms += change['duration_ms']
            
            if len(changes) > 0:
                avg_duration_ms = total_duration_ms / len(changes)
                print(f"\nğŸ“ˆ WINDOW DURATION STATS:")
                print(f"   Average window duration: {avg_duration_ms:.0f}ms")
                print(f"   Total measured duration: {total_duration_ms:.0f}ms")
        else:
            print(f"âš ï¸  No window_end changes detected during test period")
        
        print(f"\nâš¡ PERFORMANCE METRICS:")
        print(f"   Total API Calls: {metrics['total_calls']}")
        print(f"   Total Errors: {metrics['total_errors']}")
        print(f"   Success Rate: {metrics['success_rate']:.1f}%")
        print(f"   Calls per Second: {metrics['calls_per_second']:.1f}")
        
        print(f"\nâ±ï¸  RESPONSE TIME ANALYSIS:")
        print(f"   Average: {metrics['avg_response_time']:.3f}s")
        print(f"   Minimum: {metrics['min_response_time']:.3f}s")
        print(f"   Maximum: {metrics['max_response_time']:.3f}s")
        print(f"   Median: {metrics['median_response_time']:.3f}s")
        print(f"   95th Percentile: {metrics['p95_response_time']:.3f}s")
        
        # 1ì´ˆ ì´ë‚´ ìš”êµ¬ì‚¬í•­ ì²´í¬
        under_1s = sum(1 for rt in self.response_times if rt < 1.0)
        under_1s_rate = under_1s / len(self.response_times) * 100
        
        print(f"\nğŸ¯ LATENCY REQUIREMENT (< 1 second):")
        if under_1s_rate >= 95:
            print(f"   âœ… SUCCESS: {under_1s_rate:.1f}% of calls under 1s ({under_1s}/{len(self.response_times)})")
        else:
            print(f"   âš ï¸  WARNING: {under_1s_rate:.1f}% of calls under 1s ({under_1s}/{len(self.response_times)})")
        
        if self.errors:
            print(f"\nâŒ ERRORS:")
            for error in self.errors:
                print(f"   {error}")

if __name__ == "__main__":
    test = APIPerformanceTest()
    asyncio.run(test.run_test())